{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78ffcb1f-f209-4d98-8583-9c6177dc97bb",
   "metadata": {},
   "source": [
    "<center><h1>Transformers Implementation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306976d2-9c74-4039-9c16-cac883b23232",
   "metadata": {},
   "source": [
    "### Importing everything we need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccc679e-cfab-44b8-99a7-a42c9867a16c",
   "metadata": {},
   "source": [
    "In this notebook, it will be sufficient to use tensorflow to optimize our model so that we don't go into backpropagation's details and we focus on the Transformer itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b88671-1f26-48fe-9b4f-c1876eb2a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f317a5-3fad-43ee-b0ee-2bf7cdb8dc53",
   "metadata": {},
   "source": [
    "<h3>Positional Encoding</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7ea087-8482-4a21-ade9-205b941cadde",
   "metadata": {},
   "source": [
    "positional encoding shape: **(length, d_model)**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7ddf45-d195-4120-a6db-302640c6ee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          1.          0.          1.        ]\n",
      " [ 0.84147098  0.54030231  0.00999983  0.99995   ]\n",
      " [ 0.90929743 -0.41614684  0.01999867  0.99980001]]\n",
      "[[ 0.          1.          0.          1.        ]\n",
      " [ 0.84147098  0.54030231  0.00999983  0.99995   ]\n",
      " [ 0.90929743 -0.41614684  0.01999867  0.99980001]\n",
      " [ 0.14112001 -0.9899925   0.0299955   0.99955003]]\n"
     ]
    }
   ],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    PE = np.zeros((length, depth))\n",
    "    for i in range(depth):\n",
    "        for pos in range(length):\n",
    "            if(i%2==0):\n",
    "                PE[pos, i] = np.sin(pos/(10000**(i/depth)))\n",
    "            else:\n",
    "                PE[pos, i] = np.cos(pos/(10000**((i-1)/depth)))\n",
    "\n",
    "    PE = PE\n",
    "    return PE\n",
    "\n",
    "print(positional_encoding(3, 4)) # (length, depth)\n",
    "print(positional_encoding(4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e1cc5a-1901-4c35-81f8-e464f5902436",
   "metadata": {},
   "source": [
    "<h3>Positional Embedding</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3956770-dad0-4e76-b181-97242e0bb020",
   "metadata": {},
   "source": [
    "Input shape: **(batch_size, length, d_model)**<br>\n",
    "positional embedding shape: **(batch_size, length, d_model)**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14bf001a-ea9e-41af-9988-ca108f700c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape=(batch_size, length)      output_shape=(batch_size, length, depth)\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=d_model, mask_zero=True)\n",
    "\n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x+= positional_encoding(length ,self.d_model)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29990bdf-0bae-4d0b-81f3-77cf83e003f6",
   "metadata": {},
   "source": [
    "<h3>Multi-Head Attention</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6bb2af-e72f-45c1-a889-51e0b9183eb3",
   "metadata": {},
   "source": [
    "Input shape: **(batch_size, length, d_model)**<br>\n",
    "MultiHeadAttention output shape: **(batch_size, length, d_model)**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb87f7b8-db8b-42a7-96ca-878bb12c0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, heads, mask=False):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.heads = heads\n",
    "        self.mask = mask\n",
    "        self.queries = tf.keras.layers.Dense(d_model,use_bias=False) #  input_shape=(batch_size, length, d_model)\n",
    "        self.keys = tf.keras.layers.Dense(d_model,use_bias=False)\n",
    "        self.values = tf.keras.layers.Dense(d_model,use_bias=False)\n",
    "        self.out = tf.keras.layers.Dense(d_model,use_bias=False)\n",
    "\n",
    "    def call(self, q, k, v):\n",
    "        batch_size, length, _ = q.shape\n",
    "        batch_size, lengthc, _ = k.shape\n",
    "        Q, K, V = self.queries(q), self.keys(k), self.values(v)\n",
    "        # shapes = (batch_size, length, d_model)\n",
    "        Q = tf.transpose( tf.reshape( Q,shape=(batch_size, length, self.heads, self.d_model//self.heads) ), perm=(0,2,1,3))\n",
    "        K, V =[tf.transpose( tf.reshape( P,shape=(batch_size, lengthc, self.heads, self.d_model//self.heads) ), perm=(0,2,1,3)) for P in (K,V)]\n",
    "        # shapes= (batch_size, heads, length, d_model//heads=dk)\n",
    "        dk = tf.cast(self.d_model//self.heads,dtype=tf.float32)\n",
    "        mask = tf.linalg.set_diag(tf.linalg.band_part(tf.fill((length,lengthc), float('-inf')), 0, -1), tf.zeros(length)) if self.mask else tf.zeros((length,lengthc))\n",
    "        attention_values = tf.matmul(Q, tf.transpose(K, perm=(0,1,3,2))) / tf.sqrt(dk)\n",
    "        attention_weights = tf.nn.softmax(attention_values+mask)@V\n",
    "        return self.out(tf.reshape(tf.transpose(attention_weights, perm=(0,2,1,3)),shape=(batch_size, length, self.d_model))), attention_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8d2aa-51cd-45fb-8a35-b42813f0897c",
   "metadata": {},
   "source": [
    "<h3>Feed Forward Neural Network</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e226b50-3c79-4956-b6ed-8c35ff888638",
   "metadata": {},
   "source": [
    "Input shape: **(batch_size, length, d_model)**<br>\n",
    "Inner layer shape: **(batch_size, length, dff)**<br>\n",
    "FeedForward output shape: **(batch_size, length, d_model)**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfe93d8d-8502-4257-88e0-9ebc65b18cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff):\n",
    "        super().__init__()\n",
    "        self.l1 = tf.keras.layers.Dense(dff, activation=tf.keras.activations.relu)# input_shape=(batch_size, length, d_model)\n",
    "        self.l2 = tf.keras.layers.Dense(d_model)\n",
    "    def call(self, x):\n",
    "        return self.l2(self.l1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca060c41-7758-4e6b-95a3-231d3f998565",
   "metadata": {},
   "source": [
    "<h3>Encoder Layer</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108201db-356e-4af7-be37-4cbc22dbc23f",
   "metadata": {},
   "source": [
    "Input shape: **(batch_size, length, d_model)**<br>\n",
    "EncoderLayer shape: **(batch_size, length, d_model)**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40781921-36a4-4b81-b004-8bf0bb26a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, heads, dff, masked_attention=False):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, heads, masked_attention)\n",
    "        self.add1 = tf.keras.layers.Add()\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization()\n",
    "        self.FFN = FeedForward(d_model, dff)\n",
    "        self.add2 = tf.keras.layers.Add()\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        MHA,_ = self.mha(x,x,x)\n",
    "        AN1 = self.norm1(self.add1((MHA,x)))\n",
    "        F1 = self.FFN(AN1)\n",
    "        AN2 = self.norm2(self.add2((F1,AN1)))\n",
    "        return AN2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f3401a-0b26-4178-9875-bd928fd2bbd1",
   "metadata": {},
   "source": [
    "<h3>Encoder</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b80eb7-e9c7-4a62-8580-820ff9663b67",
   "metadata": {},
   "source": [
    "Input shape: **(batch_size, length, d_model)**<br>\n",
    "Encoder shape: **(batch_size, length, d_model)**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b80316-6b7f-4b83-b3ab-06f2ec29abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, N, vocab_size, d_model, heads, dff, masked_attention=False):\n",
    "        super().__init__()\n",
    "        self.positional_embedding = PositionalEmbedding(vocab_size, d_model)\n",
    "        self.encoder_layers = [EncoderLayer(d_model, heads, dff, masked_attention=False) for _ in range(N)]\n",
    "        self.N = N\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.positional_embedding(x)\n",
    "\n",
    "        for n in range(self.N):\n",
    "            x = self.encoder_layers[n](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d7f428-988f-4188-8141-438bb40d54e7",
   "metadata": {},
   "source": [
    "<h3>Decoder Layer</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5c00bb-e086-4544-aecd-dca1a896d151",
   "metadata": {},
   "source": [
    "Input shapes: **(batch_size, x_length, d_model)** and **(batch_size, context_length, d_model)**<br>\n",
    "Decoder output shape: **(batch_size, x_length, d_model)** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "468c28ab-1bcd-455a-9143-adb8355ced73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, mheads, cheads, dff, masked_cross_attention=False):\n",
    "        super().__init__()\n",
    "        self.mha1 = MultiHeadAttention(d_model, mheads, mask=True)\n",
    "        self.add1 = tf.keras.layers.Add()\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "        self.mha2 = MultiHeadAttention(d_model, cheads, masked_cross_attention)\n",
    "        self.add2 = tf.keras.layers.Add()\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "        self.FFN = FeedForward(d_model, dff)\n",
    "        self.add3 = tf.keras.layers.Add()\n",
    "        self.norm3 = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x, context):\n",
    "        MMHA, _ = self.mha1(x,x,x)\n",
    "        AN1 = self.norm1(self.add1((MMHA,x)))\n",
    "        CMHA, _ = self.mha2(AN1, context, context)\n",
    "        AN2 = self.norm2(self.add2((CMHA,AN1)))\n",
    "        F = self.FFN(AN2)\n",
    "        AN3 = self.norm3(self.add3((F,AN2)))\n",
    "        return AN3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b76095c-0a5a-4b5a-a23d-30d757e9823e",
   "metadata": {},
   "source": [
    "<h3>Decoder</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79655002-bfce-49dd-8f7e-78cb5aeb5847",
   "metadata": {},
   "source": [
    "Input shapes: **(batch_size, x_length, d_model)** and **(batch_size, context_length, d_model)**<br>\n",
    "Decoder output shape: **(batch_size, x_length, d_model)** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbbb157c-2e02-4826-ba59-3c6935087826",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, N, target_vocab_size, d_model, mheads, cheads, dff, masked_cross_attention=False):\n",
    "        super().__init__()\n",
    "        self.positional_embedding = PositionalEmbedding(target_vocab_size, d_model)\n",
    "        self.decoder_layers = [DecoderLayer(d_model, mheads, cheads, dff, masked_cross_attention) for n in range(N)]\n",
    "        self.N = N\n",
    "\n",
    "    def call(self, x, context):\n",
    "        x = self.positional_embedding(x)\n",
    "\n",
    "        for n in range(self.N):\n",
    "            x = self.decoder_layers[n](x, context)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0233dd24-ca2f-4d56-9b7e-93e2f4dbe3e6",
   "metadata": {},
   "source": [
    "<h3>Transformer</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c699b9-0420-4883-bc9a-a94fb6ad6f82",
   "metadata": {},
   "source": [
    "Input shapes: **(batch_size, x_length, d_model)** and **(batch_size, context_length, d_model)**<br>\n",
    "Transformer output shape: **(batch_size, x_length, d_model)** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eb0bff4-594e-4129-a60c-f45f43b49698",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, Ne, Nd, vocab_size, target_vocab_size, d_model, gheads, mheads, cheads, dff, masked_global_attention=False, masked_cross_attention=False):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(Ne, vocab_size, d_model, gheads, dff, masked_global_attention)\n",
    "        self.decoder = Decoder(Nd, target_vocab_size, d_model, mheads, cheads, dff, masked_cross_attention)\n",
    "        self.out = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, x, context):\n",
    "        encoded = self.encoder(context)\n",
    "        decoded = self.decoder(x, encoded)\n",
    "        logits = self.out(decoded)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9801612-3746-467a-a999-135b205eebe4",
   "metadata": {},
   "source": [
    "<h3>Let's try it out</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f6004cf-edf0-4290-8faf-a516baf2ab13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 9, 100)\n"
     ]
    }
   ],
   "source": [
    "Ne, Nd, vocab_size, target_vocab_size, batch_size, d_model, mheads, cheads, gheads, dff, lengthx, lengthc = 6, 6, 1000, 100, 32, 512, 8, 8, 8, 2046, 9, 1\n",
    "\n",
    "input = tf.random.uniform(shape=(batch_size, lengthx))\n",
    "context_input = tf.random.uniform(shape=(batch_size, lengthc))\n",
    "\n",
    "transformer = Transformer(Ne, Nd, vocab_size, target_vocab_size, d_model, gheads, mheads, cheads, dff)\n",
    "\n",
    "results = transformer(input, context_input)\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d7b7c-4784-493c-bd8d-abde00466096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
